{"meta":{"title":"개발새발 블로그","subtitle":"개발새발 블로그","description":null,"author":"Hyunkyung Ahn","url":"https://tuwhit.github.io"},"pages":[],"posts":[{"title":"Lambda, Kinesis Firehose 를 이용해서 AuroraDB에 추가된 데이터를 실시간으로 ES에 저장하기","slug":"aurora-to-es","date":"2018-02-15T04:41:08.000Z","updated":"2018-02-15T05:07:49.362Z","comments":true,"path":"2018/02/15/aurora-to-es/","link":"","permalink":"https://tuwhit.github.io/2018/02/15/aurora-to-es/","excerpt":"","text":"이번엔 Kinesis Firehose 의 목적지를 Elasticsearch로 설정해서 테스트해봤다. Elasticsearch 새 도메인 올리는데 시간이 좀 걸리니 미리 만들어 두는게 좋음. Lambda, Kinesis Firehose 를 이용해서 AuroraDB에 추가된 데이터 실시간으로 캡쳐하기 문서 참고해서 AuroraDB, Lambda 설정까지 완료 새 Elasticsearch domain을 생성 kinesis firehose가 elasticsearch 6.0은 지원을 안하니 그 아래 버전으로 생성할것. Elasticsearch 6.0 is not currently supported by Kinesis Firehose. Contact AWS Support for more information. 에러가 뜬다… 따흐흑… 위 domain에 index, type을 생성 123456789101112131415&#123; \"properties\": &#123; \"ItemID\": &#123;\"type\": \"integer\"&#125;, \"Category\": &#123;\"type\": \"text\"&#125;, \"Price\": &#123;\"type\": \"float\"&#125;, \"Quantity\": &#123;\"type\": \"integer\"&#125;, \"OrderDate\": &#123; \"type\": \"date\", \"format\": \"strict_date_optional_time||epoch_millis\" &#125;, \"DestinationState\": &#123;\"type\": \"text\" &#125;, \"ShippingType\": &#123;\"type\": \"text\"&#125;, \"Referral\": &#123;\"type\": \"text\"&#125; &#125;&#125; 새 Kinesis Firehose 를 생성 destination을 Amazon Elasticsearch service 선택 Amazon Elasticsearch Service destination에 위에서 만든 elasticsearch domain, index, type을 입력 IAM에 ES에 대한 권한이 제대로 명시돼 있는지 확인 (알아서 만들어줌) Lambda code 수정 123456789101112131415161718192021222324import boto3import jsonimport loggingfirehose = boto3.client('firehose', region_name='리전이름')stream_name = 'delivery stream 이름'def lambda_handler(event, context): # for ES firehose_data = &#123; \"ItemID\": event['ItemID'], \"Category\": event['Category'], \"Price\": event['Price'], \"Quantity\": event['Quantity'], \"OrderDate\": event['OrderDate'].split()[0] + \"T\" + event['OrderDate'].split()[1], \"DestinationState\": event['DestinationState'], \"ShippingType\": event['ShippingType'], \"Referral\": event['Referral'] &#125; firehose_data = &#123;'Data': json.dumps(firehose_data)&#125; logging.info(json.dumps(firehose_data)) result = firehose.put_record(DeliveryStreamName=stream_name,Record=firehose_data) AuroraDB 테이블에 데이터 추가 얼마후에 ES에 _search 쿼리 날려보면 데이터가 추가된것을 확인할수 있음 기타 참고 kinesis 에서 데이터가 잘 넘어가는지 CloudWatch에서 확인실패시 S3에 로그저장됨 Datetime 포맷은 ES의 Date 포맷에 맞춰서 넣을것","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"https://tuwhit.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"https://tuwhit.github.io/tags/Lambda/"},{"name":"Kinesis Firehose","slug":"Kinesis-Firehose","permalink":"https://tuwhit.github.io/tags/Kinesis-Firehose/"},{"name":"AuroraDB","slug":"AuroraDB","permalink":"https://tuwhit.github.io/tags/AuroraDB/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://tuwhit.github.io/tags/Elasticsearch/"}]},{"title":"Lambda, Kinesis Firehose 를 이용해서 AuroraDB에 추가된 데이터 실시간으로 캡쳐하기","slug":"aurora-data-streaming","date":"2018-01-23T11:23:50.000Z","updated":"2018-01-23T11:44:29.997Z","comments":true,"path":"2018/01/23/aurora-data-streaming/","link":"","permalink":"https://tuwhit.github.io/2018/01/23/aurora-data-streaming/","excerpt":"","text":"데이터 스트리밍 관련 리서치를 하다가 이런 문서가 있길래 직접 해봤다.(AuroraStream이 따로 없고 DynamoStream만 있는듯) 회사에선 AuroraDB를 써서 일단 요 실습을 따라해보는걸로. 사실 자세한건 위 링크에 다 나와있다…ㅎㅎ;; 간단히 요약하면서 중간중간 삽질한것만 추가로 기록해봤음. Kinesis 에서새로운 delivery stream을 생성하고 Destination을 S3로 선택해준뒤, 원하는 버켓을 지정해줌 AuroraDB 와 같은 리전에서 새 Lambda function 을 생성 Lambda 코드에서 stream_name 만 1번에서 만든 stream 이름으로 변경 혹시 firehose 가 다른 리전에 있다면 firehose = boto3.client(‘firehose’, region_name=’리전 이름’) 이렇게 뒤에 리전 이름 추가해줌 AuroraDB에서 원하는 테이블에 프로시저, 트리거 생성 프로시저에서 2에서 생성해준 Lambda function의 arn 으로 설정해줌 AuroraDB parameter group에서 aws_default_lambda_role 의 value 를 lambda 를 실행시킬수있는 role의 arn으로 설정 안해주면 Missing Credentials: Cannot instrantiate Lambda Client 에러남 테이블에 데이터를 추가 Lambda에서 예외처리를 따로 안해줘서 필드가 null 일땐 에러나는듯 좀있다가 S3 버킷 확인해보면 요렇게 파일이 생겨있음 그래도 에러나면 IAM 제대로 설정돼있는지 확인 ㄱㄱ","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"https://tuwhit.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"https://tuwhit.github.io/tags/Lambda/"},{"name":"Kinesis Firehose","slug":"Kinesis-Firehose","permalink":"https://tuwhit.github.io/tags/Kinesis-Firehose/"},{"name":"S3","slug":"S3","permalink":"https://tuwhit.github.io/tags/S3/"},{"name":"AuroraDB","slug":"AuroraDB","permalink":"https://tuwhit.github.io/tags/AuroraDB/"}]},{"title":"Data Pipeline로 S3에서 DynamoDB로 데이터 import 시키기","slug":"import-to-dynamodb","date":"2017-11-19T08:57:45.000Z","updated":"2017-11-19T09:45:30.000Z","comments":true,"path":"2017/11/19/import-to-dynamodb/","link":"","permalink":"https://tuwhit.github.io/2017/11/19/import-to-dynamodb/","excerpt":"","text":"이번엔 Data Pipeline을 이용해서 S3에서 DynamoDB로 데이터를 import 시키는 방법을 정리해본다. DynamoDB에 item을 생성하는데(이틀간 삽질하며) 아래의 방식들을 써봤다. AWS console에서 직접 생성 ruby SDK를 이용해서 csv 파일을 한줄한줄 읽어서 item 생성 aws dynamodb batch-write-item –request-items file://파일명 명령어를 이용(형식 맞춰줘야함) DataPipeline을 이용해서 S3의 파일을 import 1억건의 데이터를 넣는데는 1, 2번으론 무리가 있었고 3번도 파일 용량제한이 있는지 에러를 내뱉었다. 결국 Data Pipeline으로… Data Pipeline 을 생성하면 DynamoDB 템플릿이 존재한다. Import DynamoDB backup data from S3 을 선택하고 생성해준다. 그리고 Parameter 들만 잘 설정해주면 됨. 유의해야할것은 Data Pipeline을 생성한 리전과 S3 bucket, DynamoDB의 리전이 같아야한다. 안그러면 에러를 뿜뿜함. 아니 리전 입력하라고 해놓고 왜 에러나는지 모를… 파일형식도 맞춰야한다. 열심히 구글링을 해봐도 없어서 새로 Data Pipeline을 생성해서 반대로 Export 시켜봤다 ㅠㅠ 123&#123;\"amount\":&#123;\"s\":\"8\"&#125;,\"shop_id\":&#123;\"s\":\"100000\"&#125;,\"gender\":&#123;\"s\":\"1\"&#125;,\"Id\":&#123;\"n\":\"1\"&#125;,\"user_id\":&#123;\"s\":\"70167727\"&#125;,\"date\":&#123;\"s\":\"2017-01-22\"&#125;,\"birth_year\":&#123;\"s\":\"1955\"&#125;&#125;&#123;\"amount\":&#123;\"s\":\"17\"&#125;,\"shop_id\":&#123;\"s\":\"100001\"&#125;,\"gender\":&#123;\"s\":\"0\"&#125;,\"Id\":&#123;\"n\":\"2\"&#125;,\"user_id\":&#123;\"s\":\"29015489\"&#125;,\"date\":&#123;\"s\":\"2017-07-05\"&#125;,\"birth_year\":&#123;\"s\":\"2010\"&#125;&#125;&#123;\"amount\":&#123;\"s\":\"11\"&#125;,\"shop_id\":&#123;\"s\":\"100001\"&#125;,\"gender\":&#123;\"s\":\"1\"&#125;,\"Id\":&#123;\"n\":\"4\"&#125;,\"user_id\":&#123;\"s\":\"90567446\"&#125;,\"date\":&#123;\"s\":\"2017-01-14\"&#125;,\"birth_year\":&#123;\"s\":\"1953\"&#125;&#125; 그 결과, item별로 {필드1: {데이터 형식: 값}, 필드2: {데이터 형식: 값}} 요런 형태로 파일이 만들어졌다. 그래서 기존의 csv 파일을 위 형태로 컨버팅후(스크립트 만들어서 돌림ㅠㅠ) Data Pipeline을 실행시켜보니 잘 들어감! 그런데 write 속도가 너무 느려서 DynamoDB의 write capacity 값을 올려줬는데도 일정값 이상으로 안올라오길래 왜그런가 했더니 Data Pipeline 설정에 myDDBWriteThroughputRatio 필드가 있었다.(0 ~ 1 사이의 값으로 입력가능) 1으로 수정해주니 입력값으로 잘 올라옴. 다른건 몰라도 이제 DynamoDB에 데이터 입력하는덴 전문가된듯. -_-","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"https://tuwhit.github.io/tags/AWS/"},{"name":"S3","slug":"S3","permalink":"https://tuwhit.github.io/tags/S3/"},{"name":"DynamoDB","slug":"DynamoDB","permalink":"https://tuwhit.github.io/tags/DynamoDB/"},{"name":"Data Pipeline","slug":"Data-Pipeline","permalink":"https://tuwhit.github.io/tags/Data-Pipeline/"}]},{"title":"S3에 있는 csv 파일을 AuroraDB로 import 시키기","slug":"import-s3-to-aurora","date":"2017-11-16T14:14:10.000Z","updated":"2017-11-16T15:01:46.000Z","comments":true,"path":"2017/11/16/import-s3-to-aurora/","link":"","permalink":"https://tuwhit.github.io/2017/11/16/import-s3-to-aurora/","excerpt":"","text":"데이터 분석 관련 프로젝트를 진행중이라 간만에 포스팅을 한다. 아마 당분간 프로젝트를 진행하며 겪었던 삽질기를 계속 포스팅하지 않을까 싶음… 처음 해보는것들 투성이라 팀원들이 모두 프로야근러가 되었다. 흑흑ㅠㅠ 오늘은 문서가 잘 정리돼있어서 꽤 쉽게 클리어했던 S3에 있는 csv 파일을 AuroraDB에 import 시키는 방법을 정리해본다. AuroraDB instance를 생성하고 IAM role(case는 물론 RDS로 선택)을 만들어준다. 생성후 permission 탭에서 Attach policy를 클릭하여 S3에 Access할수 있도록 AmazonS3FullAccess 를 추가해준다. 그리고 다시 RDS로 돌아가 Parameter group을 생성해준다. 여기서 Type은 DB Cluster Parameter Group 으로 설정한다. 생성후에 aurora_load_from_s3_role 의 value 값을 위에서 만든 IAM role ARN로 입력해준다. cluster 메뉴에서 해당 cluster 수정 페이지로 이동하여 DB Cluster Parameter Group을 위에서 생성해준 걸로 설정해준다. 다음 페이지로 넘어가서 Apply Immediately 선택후 완료. 다시 cluster 메뉴로 돌아와 해당 cluster 선택 후 Manage IAM roles 페이지로 이동하여 위에서 만들어준 IAM role을 추가해준다. 여기까지가 데이터를 로드하기위한 준비 끝. 1mysql -h [DB Endpoint] -P [port] -u [user name] -p 이후 패스워드를 입력하면 해당 AuroraDB로 접속하게된다. 123load data from s3 &apos;s3-[region]://[bucket name]/[file name]&apos;into table [table name]fields terminated by &apos;,&apos;; 이렇게 하면 s3에 있는 csv 파일의 데이터를 지정한 테이블로 로드하게 된다. 1억 row 짜리 데이터 올리는데 한시간가량 걸렸던것 같음. 위 명령어만으로 로드하면 필드명으로 구분이 안되고 파일에 입력된 순서대로 DB에 저장되니 유의하자. 로드할때 여러가지 옵션이 있는데 여기에서 확인할 수 있다.","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"https://tuwhit.github.io/tags/AWS/"},{"name":"S3","slug":"S3","permalink":"https://tuwhit.github.io/tags/S3/"},{"name":"AuroraDB","slug":"AuroraDB","permalink":"https://tuwhit.github.io/tags/AuroraDB/"},{"name":"Database","slug":"Database","permalink":"https://tuwhit.github.io/tags/Database/"},{"name":"RDS","slug":"RDS","permalink":"https://tuwhit.github.io/tags/RDS/"}]},{"title":"AWS 도커 컨테이너 배포 자동화 실습","slug":"code-deploy","date":"2017-10-27T12:51:05.000Z","updated":"2017-11-16T14:12:41.000Z","comments":true,"path":"2017/10/27/code-deploy/","link":"","permalink":"https://tuwhit.github.io/2017/10/27/code-deploy/","excerpt":"","text":"3일전 Gaming on AWS에 참석해서 ‘도커 컨테이너 배포 자동화 실습’을 진행했다. 회사에서도 도커 컨테이너를 이용해서 배포를 하고있어서(수동이지만) 적용해볼 수 있을것 같다. 당일에는 실습자료를 보고 따라하기 급급했어서 다시 한번 정리해봤다. CodePipeline으로 배포 프로세스를 구성하고 S3에 저장된 소스코드를 CodeBuild를 통해 컴파일 및 컨테이너 이미지 생성한다. 그리고 CloudFormation을 이용해 ECS에 배포한다. CodePipeline 생성 Source provider는 소스코드가 저장된 S3 버킷으로 설정하고 CodeBuild를 build provider로 선택 코드가 build되어 생성된 컨테이너 이미지는 ECR repository에 저장 환경 설정 파일도 S3에 저장하고 CodePipeline 에서 해당 파일을 사용하는 Source 액션 추가 Dockerize 하는 액션 추가 (여기까지가 Build 스테이지) Deploy 스테이지 추가 CloudFormation으로 환경설정 파일을 참조하여 deploy 설정 완료 후 S3에 환경 설정 파일, 어플리케이션을 업로드하면 CodePipeline 에서 변경사항을 감지하여 배포작업을 수행한다. 왕신기. 추가적으로 Lambda를 이용해서 Blue/Green 배포도 가능하다. 현재 리얼 환경이 아닌 곳으로 배포하고 수동 승인과정을 거치면 환경을 Swap 하도록 할 수 있다. 이거슨 빙산의 일각이다 간단히 정리해놔서 그렇지 실제로 콘솔에서 설정해줘야 하는 것들이 굉장히 많았다. (ECS, ELB, ECR, IAM 등등…) 그 하나하나를 이해하기는 좀 어려워서 따로 공부가 필요할 것 같다. 그리고 실습에서 제공된 환경설정파일들도 실제 서비스 환경설정파일들이랑 같이 보면 좋을듯.","categories":[],"tags":[{"name":"deploy","slug":"deploy","permalink":"https://tuwhit.github.io/tags/deploy/"},{"name":"AWS","slug":"AWS","permalink":"https://tuwhit.github.io/tags/AWS/"},{"name":"CodePipeline","slug":"CodePipeline","permalink":"https://tuwhit.github.io/tags/CodePipeline/"}]},{"title":"개복치같은 서버를 살리기위한 삽질기(ing)","slug":"server-sabjil","date":"2017-10-13T11:15:21.000Z","updated":"2017-10-13T11:29:18.000Z","comments":true,"path":"2017/10/13/server-sabjil/","link":"","permalink":"https://tuwhit.github.io/2017/10/13/server-sabjil/","excerpt":"","text":"작년에 신규 프로젝트를 진행하면서 기존 ruby 서버가 아닌 python 으로 별도의 서버를 띄웠다. Java로 된 별도의 암호화모듈을 사용해야해서 Py4J을 이용했다. 그런데 이 라이브러리의 문제인지 메모리 누수 때문인지 원인은 모르겠지만 2-3주정도 주기로 암호화모듈쪽에서 에러가 나기 시작하면서 그 이후의 모든 요청에서 같은 에러가 발생했다. 기존에 url lib 를 썼던것을 requests 를 사용하도록 수정했지만 에러 발생주기가 조금 길어졌을 뿐 해결이 되지않았다. 일단 원인을 찾는것은 뒤로 미루고 Lambda와 Cloud Watch를 이용해서 매일 새벽2시에 인스턴스를 리붓시키도록 했다. 1234567891011var AWS = require('aws-sdk');exports.handler = (event, context, callback) =&gt; &#123; var ec2 = new AWS.EC2(&#123;region: 'ap-northeast-2'&#125;); ec2.rebootInstances(&#123;InstanceIds : ['instance-ID'] &#125;,function (err, data) &#123; if (err) console.log(err.stack); else console.log(data); context.done(err,data); &#125;);&#125;; 이후 몇달간 서버에 이상이 없는듯 하더니 어느날 아예 500에러가 나기시작했다. -_- 원인을 찾아보려 서버에 접속해봤더니 컨테이너가 아예 없었다. 리붓하면서 컨테이너가 제대로 생성되지 않은것 같았다. Docker 관련 지식이 얕아 원인을 알수가 없어서 일단 인스턴스를 새로 생성하는 것으로 해결을 했다. 그리고 UptimeRobot을 이용해 5분에 한번 서버에 request를 보내고, 문제가 있으면 slack으로 alert message를 남기도록 했다. 이걸 5분만에 설정할수있다니 21세기 스고이 그런데 깜빡하고 Lambda 코드에 바뀐 인스턴스 ID로 수정하지 않아서(아오) 3주뒤 또 암호화 모듈 에러가 발생했다. 이런 휴먼에러를 발생시키지 않기위해 코드를 몇줄 더 추가했다. ㅠㅠ12345678910111213141516171819202122232425262728293031323334353637383940414243444546var AWS = require('aws-sdk');var https = require('https');var util = require('util');var POST_OPTIONS = &#123; hostname: 'hooks.slack.com', path: 'slack web-hook url', method: 'POST',&#125;;exports.handler = (event, context, callback) =&gt; &#123; var ec2 = new AWS.EC2(&#123;region: 'ap-northeast-2'&#125;); const failed_message = &#123; channel: 'service-alerts', text: 'Instace Reboot Failed' &#125;; // check if instance exists ec2.describeInstances(&#123;InstanceIds : ['instance-ID']&#125;, function (err, data)&#123; if (err) &#123; // if doesn't exist, send slack alert var r = https.request(POST_OPTIONS, function(res) &#123; res.setEncoding('utf8'); res.on('data', function (data) &#123; context.succeed(\"Message Sent: \" + data); &#125;); &#125;).on(\"error\", function(e) &#123;context.fail(\"Failed: \" + e);&#125; ); r.write(util.format(\"%j\", failed_message)); r.end(); &#125; else &#123; // exist // reboot instance ec2.rebootInstances(&#123;InstanceIds : ['instance-ID'] &#125;,function (err, data) &#123; if (err) &#123; // send slack alert var r = https.request(POST_OPTIONS, function(res) &#123; res.setEncoding('utf8'); res.on('data', function (data) &#123; context.succeed(\"Message Sent: \" + data); &#125;); &#125;).on(\"error\", function(e) &#123;context.fail(\"Failed: \" + e);&#125; ); r.write(util.format(\"%j\", failed_message)); r.end(); &#125; else console.log(data); context.done(err,data); &#125;); &#125; &#125;);&#125;; 리붓시킬 인스턴스를 먼저 찾고 없으면 슬랙으로 alert message를 보내고, 있으면 해당 인스턴스를 리붓시킨다. 리붓시 에러가 나도 슬랙으로 alert message를 보낸다. 애초에 에러의 원인을 찾아서 해결했어야하는데 다른일들로 시간적 여유가 없다보니 그때그때 서버만 살리고 뒷전으로 미뤄뒀던 것에 반성을… 틈틈히 시간내서 원인파악을 해야겠다.","categories":[],"tags":[{"name":"Server","slug":"Server","permalink":"https://tuwhit.github.io/tags/Server/"},{"name":"Lambda","slug":"Lambda","permalink":"https://tuwhit.github.io/tags/Lambda/"},{"name":"node.js","slug":"node-js","permalink":"https://tuwhit.github.io/tags/node-js/"},{"name":"UptimeRobot","slug":"UptimeRobot","permalink":"https://tuwhit.github.io/tags/UptimeRobot/"},{"name":"Monitoring","slug":"Monitoring","permalink":"https://tuwhit.github.io/tags/Monitoring/"}]},{"title":"UI와 UX에 대한 개념 정리","slug":"til","date":"2017-09-26T13:48:04.000Z","updated":"2017-09-26T15:03:21.000Z","comments":true,"path":"2017/09/26/til/","link":"","permalink":"https://tuwhit.github.io/2017/09/26/til/","excerpt":"","text":"프로젝트 진행중에 UX 설계를 해볼일이 생겼는데, 디알못이라 뭘 어떻게 해야할지 영 감이 잘 안잡혀서 일단 UI, UX의 개념이라도 정리해봤다.(정리하다보니 생각났는데 옛날에 Human Centered Design 스터디를 한적이 있는데, 그것도 UX Design에 속하는 거였나 싶음) UI(User Interface) 일련의 화면, 페이지 및 장치와 상호작용할 때 사용하는 시각적 요소 UX(User Experience) 회사, 서비스 및 제품과 상호 작용하는 사용자의 경험 UX Design 실제 필드에서 사용자를 관찰하고, 그 결과를 바탕으로 디자인 누가, 왜, 무엇을, 어떻게 사용하는지를 고려해야함 어떤 목적인지, 어떤 의도가 있는지, 어떻게 쓰였으면 좋겠는지에 대해 고민 필요 UI와 UX의 차이점(에 대한 전문가들의 생각) UX는 문제를 해결하기위한 사용자의 여정에 포커스를 두고 UI는 제품 표면의 모습과 기능에 초점을 맞춘다. - Ken Norton UX 디자이너는 디자인 프로세스의 개념적 측면에 관심을 가지기 때문에 UI 디자이너는 보다 확실한 요소에 집중할 수 있다. - Andy Budd UX와 UI 디자인은 서로 비교할 수 없는 두가지이므로 차이가 없다. -Craig Morrision UI는 일반적으로 화면 주변의 시각적 디자인 및 정보 디자인에 관한것이다. UX는 완벽한 경험에 관한 것이므로 화면과 관련이 없을 수 있다. - Patrick Neema UI는 제품에 중점을 두고 있으며 일련의 스냅샷을 제시간에 제공한다. UX는 사용자 및 제품을 통한 이동에 초점을 맞춘다. - Scott Jenson UX는 사용자가 제품을 사용하여 얻은 전반적인 경험이며 UI는 사용자가 실제로 상호 작용하고 볼수있는 것이다. - Clayton Yan API 로직을 고려하면서 UX 설계를 하려니 쉬운일이 아닌것같다. UX를 우선으로 하자니 로직 개선하기가 빡세고, 쉽게 가자니 UX가 좋지 않은것 같고… 엉엉","categories":[],"tags":[{"name":"UI","slug":"UI","permalink":"https://tuwhit.github.io/tags/UI/"},{"name":"UX","slug":"UX","permalink":"https://tuwhit.github.io/tags/UX/"},{"name":"Design","slug":"Design","permalink":"https://tuwhit.github.io/tags/Design/"}]},{"title":"블로그 개설","slug":"first-post","date":"2017-09-24T12:00:45.000Z","updated":"2017-09-26T12:21:32.000Z","comments":true,"path":"2017/09/24/first-post/","link":"","permalink":"https://tuwhit.github.io/2017/09/24/first-post/","excerpt":"","text":"Github Pages, Hexo 로 블로그 개설! Jekyll을 이용해서 만들까 하다가 Ruby는 회사에서 많이 쓰니 Node.js 기반인 Hexo로 선택했다. 근데 뭐 Node.js 까막눈이어도 눈칫껏 만져보니 기존 테마에 살짝 커스텀하는 정도는 금방 하는듯. Markdown 문법도 잘 몰라서 Markdown 작성법 보면서 이래저래 써보는 중인데 꽤 재밌다. 블로그 메뉴를 어떻게 나눌지, footer 엔 어떤 위젯을 넣을지, 로고는 뭘로 할지 고민. 10대때 열심히 네이버 블로그 꾸미던 시절 생각난다. 하악하악 재밌어! Daily 테마 위키에 comment field 추가하려면 _config.yml 파일에disqus_shortname: your-disqus-shortname 만 추가해주면 된다고 했는데 코멘트 영역이 안뜸…^ㅅㅠ 다행히 disqus 홈페이지에 들어가보니 site - installation 메뉴에 코드가 제공돼있었다.1234567891011121314151617181920&lt;div id=\"disqus_thread\"&gt;&lt;/div&gt;&lt;script&gt;/*** RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*//*var disqus_config = function () &#123;this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variablethis.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable&#125;;*/(function() &#123; // DON'T EDIT BELOW THIS LINEvar d = document, s = d.createElement('script');s.src = 'https://tuwhit.disqus.com/embed.js';s.setAttribute('data-timestamp', +new Date());(d.head || d.body).appendChild(s);&#125;)();&lt;/script&gt;&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=\"https://disqus.com/?ref_noscript\"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt; Disqus가 들어갈 부분에 위 코드를 넣으니 해결! 테마 적용후 deploy 했는데 반영되는데 시간이 꽤 걸리나보다. 계속 깨져보이길래 제대로 deploy 안된줄알고 구글링중이었는데, 몇분 지나니까 잘 반영돼 있음.","categories":[],"tags":[{"name":"blog","slug":"blog","permalink":"https://tuwhit.github.io/tags/blog/"},{"name":"github","slug":"github","permalink":"https://tuwhit.github.io/tags/github/"},{"name":"hexo","slug":"hexo","permalink":"https://tuwhit.github.io/tags/hexo/"}]}]}